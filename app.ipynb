{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHsyAXQ2BnF4"
      },
      "outputs": [],
      "source": [
        "!pip3 install webcolors \n",
        "!pip3 install selenium\n",
        "!pip3 install bs4\n",
        "!pip3 install thecolorapi\n",
        "'''\n",
        "\n",
        "!pip3 install pinterest-api\n",
        "!pip3 install oauth2\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgvKBGBbZ7MQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from scipy.spatial import KDTree\n",
        "import webcolors\n",
        "import os\n",
        "import random\n",
        "#from pinterest import Api\n",
        "import requests, json\n",
        "import subprocess\n",
        "import sys\n",
        "from base64 import b64encode\n",
        "import urllib.request\n",
        "from selenium import webdriver\n",
        "from urllib.request import urlopen\n",
        "import re\n",
        "#import pinterest\n",
        "import requests \n",
        "from bs4 import BeautifulSoup \n",
        "from datetime import datetime\n",
        "import math\n",
        "from thecolorapi import color as thecolorapi_color\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import time\n",
        "\n",
        "testurl = 'https://www.pinterest.com/miraculouswip/flowers/'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yK3-Cjo6DMZ3"
      },
      "outputs": [],
      "source": [
        "#https://stackoverflow.com/questions/48225334/extracting-data-from-pinterest-using-beautifulsoup-python\n",
        "#couldnt figure ^ out but could be useful\n",
        "\n",
        "def getdata(url): \n",
        "    r = requests.get(url) \n",
        "    return r.text \n",
        "def checkURL(url):\n",
        "  if 'www.pinterest.com/' in url:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def getImages(url):\n",
        "  if checkURL(url):\n",
        "    htmldata = getdata(url) \n",
        "    soup = BeautifulSoup(htmldata, 'html.parser')\n",
        "\n",
        "    urlarr = []\n",
        "    for item in soup.find_all('img'):\n",
        "      urlarr.append(item['src'])\n",
        "    return urlarr\n",
        "  else:\n",
        "    print(\"Invalid pinterest url\")\n",
        "def getImageFiles(url):\n",
        "  skiplist = {'1e78a2658daa724a58773b2bdf98b68c.jpg', '37f894920d87d43da19cd5d9760e121c.jpg'}\n",
        "  urlarr = getImages(url)\n",
        "  foldername = f'pins_{datetime.now()}'\n",
        "  os.mkdir(foldername)\n",
        "  os.chdir(foldername)\n",
        "  fnamearr = []\n",
        "  for imageurl in urlarr:\n",
        "    rev = imageurl[::-1]\n",
        "    print(rev[::-1])\n",
        "    filename = rev[:rev.find('/')]\n",
        "    filename = filename[::-1]\n",
        "\n",
        "    if filename in skiplist:\n",
        "      continue\n",
        "    fnamearr.append(filename)\n",
        "\n",
        "    urllib.request.urlretrieve(imageurl, filename)\n",
        "\n",
        "    img = Image.open(filename)\n",
        "\n",
        "    img.show()\n",
        "  os.chdir('..')\n",
        "  return fnamearr, foldername\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def randrgf_img(img_og, numsamples=1000, disp = False, mode = \"RGB\"):\n",
        "  img_og = img_og.convert(mode)\n",
        "  imgarr = np.array(img_og)\n",
        "  cellarr = []\n",
        "  for _ in range(numsamples):\n",
        "    i = random.randint(0, len(imgarr)-1)\n",
        "    j = random.randint(0, len(imgarr[0])-1)\n",
        "    cell = imgarr[i][j]\n",
        "    if tuple(cell) in colornamedict.keys():\n",
        "        tup = colornamedict[tuple(cell)]\n",
        "    else:\n",
        "      tup = convert_rgb_to_names(tuple(cell)) \n",
        "      colornamedict[tuple(cell)] = tup\n",
        "    r = cell[0]\n",
        "    g = cell[1]\n",
        "    b = cell[2]\n",
        "    cellarr.append([i,j,r,g,b, tup[0], tup[1],huecalc(r,g,b),satcalc(r,g,b),lightness(r,g,b),rgb_val(r,g,b)])\n",
        "\n",
        "  #print(cellarr)\n",
        "  imgpd = pd.DataFrame(columns=[\"row\", \"column\", \"R\", \"G\", \"B\", \"name\", \"distance\", \"hue\", \"saturation\", \"lightness\", \"val\"], data = cellarr)\n",
        "  imgpd['distance'] /= 255\n",
        "  if disp:\n",
        "    print(imgpd.name.value_counts().head(10))\n",
        "  #print(imgpd)\n",
        "  return imgpd\n",
        "\n",
        "def assemble_df_direct(url, numsamples = 1000,disp= False):\n",
        "  #print(\"Assemble_direct\")\n",
        "  skiplist = {'1e78a2658daa724a58773b2bdf98b68c.jpg', '37f894920d87d43da19cd5d9760e121c.jpg'}\n",
        "  urlarr = getImages(url)\n",
        "  fnamearr = []\n",
        "  df_arr = []\n",
        "  for imageurl in urlarr:\n",
        "    rev = imageurl[::-1]\n",
        "    if disp:\n",
        "      print(rev[::-1])\n",
        "    filename = rev[:rev.find('/')]\n",
        "    filename = filename[::-1]\n",
        "\n",
        "    if filename in skiplist:\n",
        "      continue\n",
        "    fnamearr.append(filename)\n",
        "\n",
        "    urllib.request.urlretrieve(imageurl, filename)\n",
        "\n",
        "    img = Image.open(filename)\n",
        "\n",
        "    df_arr.append(randrgf_img(img,numsamples=numsamples,disp = disp))#does HSL too\n",
        "  \n",
        "\n",
        "  returnpd = pd.concat(df_arr, sort = False)\n",
        "  return returnpd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7bIkCZmpxhPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEQTC1pEoO_k"
      },
      "outputs": [],
      "source": [
        "def assemble_df(filearr, folder_name, numsamples=1000):\n",
        "  os.chdir(f'/content/{folder_name}')\n",
        "  dfarr = []\n",
        "  for file in filearr:\n",
        "    temppd = HSLanalyzer(file, numsamples)\n",
        "    temppd.assign(fname=[file for i in range(len(temppd[\"R\"]))])\n",
        "    dfarr.append(temppd)\n",
        "\n",
        "  returnpd = pd.concat(dfarr, sort = False)\n",
        "  os.chdir('../')\n",
        "  return returnpd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRPXW4qAduJf"
      },
      "outputs": [],
      "source": [
        "def convert_rgb_to_names(rgb_tuple):\n",
        "    \n",
        "    # a dictionary of all the hex and their respective names in css3\n",
        "    css3_db = webcolors.CSS3_HEX_TO_NAMES\n",
        "    names = []\n",
        "    rgb_values = []\n",
        "    for color_hex, color_name in css3_db.items():\n",
        "        names.append(color_name)\n",
        "        rgb_values.append(webcolors.hex_to_rgb(color_hex))\n",
        "    \n",
        "    kdt_db = KDTree(rgb_values)\n",
        "    distance, index = kdt_db.query(rgb_tuple)\n",
        "    return names[index], distance\n",
        "\n",
        "def convert_hsl_to_rgb(hsl_tuple):\n",
        "  hsl_tuple[0] = round(hsl_tuple[0])\n",
        "  hsl_tuple[1] = round(100*hsl_tuple[1])\n",
        "  hsl_tuple[2] = round(100*hsl_tuple[2])\n",
        "  color = thecolorapi_color(hsl = tuple(hsl_tuple))\n",
        "  return color.rbg\n",
        "def convert_hsl_to_name(hsl_tuple):\n",
        "  h = round(hsl_tuple[0])\n",
        "  s = round(100*hsl_tuple[1])\n",
        "  l = round(100*hsl_tuple[2])\n",
        "  result = requests.get(f\"https://www.thecolorapi.com/id?hsl={h},{s}%,{l}%&format=json\")\n",
        "  return result.json()[\"name\"][\"value\"]\n",
        "\n",
        "\n",
        "def convert_hsl_to_hex(hsl_tuple):\n",
        "  h = round(hsl_tuple[0])\n",
        "  s = round(100*hsl_tuple[1])\n",
        "  l = round(100*hsl_tuple[2])\n",
        "  result = requests.get(f\"https://www.thecolorapi.com/id?hsl={h},{s}%,{l}%&format=json\")\n",
        "  return result.json()[\"hex\"][\"clean\"]\n",
        "\n",
        "def convert_hsl_to_rgb(hsl_tuple):\n",
        "  h = round(hsl_tuple[0])\n",
        "  s = round(100*hsl_tuple[1])\n",
        "  l = round(100*hsl_tuple[2])\n",
        "  result = requests.get(f\"https://www.thecolorapi.com/id?hsl={h},{s}%,{l}%&format=json\")\n",
        "  rgb= result.json()[\"rgb\"]\n",
        "  return (rgb['r'], rgb['g'], rgb['b'])\n",
        "\n",
        "def convert_hsl_to_json(hsl_tuple):\n",
        "  h = round(hsl_tuple[0])\n",
        "  s = round(100*hsl_tuple[1])\n",
        "  l = round(100*hsl_tuple[2])\n",
        "  result = requests.get(f\"https://www.thecolorapi.com/id?hsl={h},{s}%,{l}%&format=json\")\n",
        "  return result.json()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGGDkaWlfcUx"
      },
      "outputs": [],
      "source": [
        " \n",
        "checkFile = \"colornamedict.csv\"\n",
        " \n",
        " \n",
        " \n",
        "if os.path.isfile(checkFile):\n",
        "  pathExists = True\n",
        "  colornamedict = {}#CHANGE ONCE I FIGURE OUT HOW TO FORMAT COLORDICT CSV\n",
        "else:\n",
        "  pathExists = False\n",
        "  colornamedict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTkQLg477m0q"
      },
      "outputs": [],
      "source": [
        "def huecalc(r,g,b):\n",
        "  r /= 255\n",
        "  g /= 255\n",
        "  b /= 255\n",
        "  cmax = max(r,g,b)\n",
        "  cmin = min(r,g,b)\n",
        "  delta = cmax - cmin\n",
        "  if delta == 0:\n",
        "    return 0\n",
        "  elif cmax == r:\n",
        "    return 60*(((g-b)/delta)%6)\n",
        "  elif cmax == g:\n",
        "    return 60*(((b-r)/delta)+2)\n",
        "  elif cmax == b:\n",
        "    return 60*(((r-g)/delta)+4)\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "def satcalc(r,g,b):\n",
        "  lightcalc = lightness(r,g,b)\n",
        "  r /= 255\n",
        "  g /= 255\n",
        "  b /= 255\n",
        "  cmax = max(r,g,b)\n",
        "  cmin = min(r,g,b)\n",
        "  delta = cmax - cmin\n",
        "  if delta == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    return (delta/(1-abs(2*lightcalc - 1)))\n",
        "\n",
        "def lightness(r,g,b):\n",
        "  r /= 255\n",
        "  g /= 255\n",
        "  b /= 255\n",
        "  cmax = max(r,g,b)\n",
        "  cmin = min(r,g,b)\n",
        "  return ((cmax+cmin)/2)\n",
        "\n",
        "def rgb_val(r,g,b):\n",
        "  return (max(r,g,b)/255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0-lfC0UcJEv"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def singlecell_rgf(imgpath = \"/content/test.jpg\"):\n",
        "  mode = \"RGB\"\n",
        "  img_og = Image.open(imgpath).convert(mode)\n",
        "  imgarr = np.array(img_og)\n",
        "  cellarr = []\n",
        "  for i in tqdm (range (len(imgarr)),desc=\"Row...\"):\n",
        "    row = imgarr[i]\n",
        "    for j, cell in enumerate(row):\n",
        "      if tuple(cell) in colornamedict.keys():\n",
        "        tup = colornamedict[tuple(cell)]\n",
        "      else:\n",
        "        tup = convert_rgb_to_names(tuple(cell))\n",
        "        colornamedict[tuple(cell)] = tup\n",
        "      cellarr.append([i,j,cell[0], cell[1], cell[2], tup[0], tup[1]])\n",
        "  imgpd = pd.DataFrame(columns=[\"row\",\"column\", \"R\", \"G\", \"B\", \"name\", \"distance\"], data = cellarr)\n",
        "  print(imgpd.name.value_counts().head(10))\n",
        "  return imgpd\n",
        "\n",
        "\n",
        "def multicell_rgf(stepsize= 5,imgpath = \"/content/test.jpg\"):\n",
        "  mode = \"RGB\"\n",
        "  img_og = Image.open(imgpath).convert(mode)\n",
        "  imgarr = np.array(img_og)\n",
        "  cellarr = []\n",
        "\n",
        "  for i in tqdm (range (0, len(imgarr), stepsize),desc=\"Rows completed\"):\n",
        "    \n",
        "    row = imgarr[i:min(i+stepsize, len(imgarr))]\n",
        "    rl = len(row)\n",
        "    #print(f\"row[0]: {row[0]}\")\n",
        "    for j in range(0,len(row[0]),stepsize):\n",
        "      #print(f\"{i},{j}\")\n",
        "      cell = row[:,j:min(j+stepsize, len(imgarr[0]))]\n",
        "      cl = len(cell)\n",
        "      avgcell = [round(np.average(cell[:,:,0])), round(np.average(cell[:,:,1])),round(np.average(cell[:,:,2]))]\n",
        "      if tuple(avgcell) in colornamedict.keys():\n",
        "        tup = colornamedict[tuple(avgcell)]\n",
        "      else:\n",
        "        tup = convert_rgb_to_names(tuple(avgcell))\n",
        "        colornamedict[tuple(avgcell)] = tup\n",
        "      temp = []\n",
        "      temp.append(i)\n",
        "      temp.append(j)\n",
        "      temp.append(rl)\n",
        "      temp.append(cl)\n",
        "      temp.append(avgcell[0])\n",
        "      temp.append(avgcell[1])\n",
        "      temp.append(avgcell[2])\n",
        "      temp.append(tup[0])\n",
        "      temp.append(tup[1])\n",
        "      \n",
        "      cellarr.append(temp)\n",
        "  imgpd = pd.DataFrame(columns=[\"row(top left ind)\",\"column(top left ind)\", \"rowlength\", \"collength\", \"R\", \"G\", \"B\", \"name\", \"distance\"], data = cellarr)\n",
        "  print(imgpd.name.value_counts().head(10))\n",
        "  return imgpd\n",
        "\n",
        "\n",
        "\n",
        "def randrgf(imgpath = \"/content/test.jpg\", numsamples=1000, disp = False):\n",
        "  mode = \"RGB\"\n",
        "  img_og = Image.open(imgpath).convert(mode)\n",
        "  imgarr = np.array(img_og)\n",
        "  cellarr = []\n",
        "  for _ in range(numsamples):\n",
        "    i = random.randint(0, len(imgarr)-1)\n",
        "    j = random.randint(0, len(imgarr[0])-1)\n",
        "    cell = imgarr[i][j]\n",
        "    if tuple(cell) in colornamedict.keys():\n",
        "        tup = colornamedict[tuple(cell)]\n",
        "    else:\n",
        "      tup = convert_rgb_to_names(tuple(cell)) \n",
        "      colornamedict[tuple(cell)] = tup\n",
        "    \n",
        "    cellarr.append([i,j,cell[0], cell[1], cell[2], tup[0], tup[1]])\n",
        "\n",
        "  #print(cellarr)\n",
        "  imgpd = pd.DataFrame(columns=[\"row\", \"column\", \"R\", \"G\", \"B\", \"name\", \"distance\"], data = cellarr)\n",
        "\n",
        "  if disp:\n",
        "    print(imgpd.name.value_counts().head(10))\n",
        "  #print(imgpd)\n",
        "  return imgpd\n",
        "\n",
        "def randrgf_img(img_og, numsamples=1000, disp = False, mode = \"RGB\"):\n",
        "  img_og = img_og.convert(mode)\n",
        "  imgarr = np.array(img_og)\n",
        "  cellarr = []\n",
        "  for _ in range(numsamples):\n",
        "    i = random.randint(0, len(imgarr)-1)\n",
        "    j = random.randint(0, len(imgarr[0])-1)\n",
        "    cell = imgarr[i][j]\n",
        "    if tuple(cell) in colornamedict.keys():\n",
        "        tup = colornamedict[tuple(cell)]\n",
        "    else:\n",
        "      tup = convert_rgb_to_names(tuple(cell)) \n",
        "      colornamedict[tuple(cell)] = tup\n",
        "    \n",
        "    cellarr.append([i,j,cell[0], cell[1], cell[2], tup[0], tup[1]])\n",
        "\n",
        "  #print(cellarr)\n",
        "  imgpd = pd.DataFrame(columns=[\"row\", \"column\", \"R\", \"G\", \"B\", \"name\", \"distance\"], data = cellarr)\n",
        "\n",
        "  if disp:\n",
        "    print(imgpd.name.value_counts().head(10))\n",
        "  #print(imgpd)\n",
        "  return imgpd\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "  \n",
        "    z = np.exp(-x)\n",
        "    sig = 1 / (1 + z)\n",
        "\n",
        "    return sig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqxwnAdcq70Q"
      },
      "outputs": [],
      "source": [
        "def HSLanalyzer(imgpath = \"/content/test.jpg\", numsamples = 1000):\n",
        "  testpd = randrgf(imgpath, numsamples)\n",
        "  hue = []\n",
        "  sat = []\n",
        "  light = []\n",
        "  val = []\n",
        "  for index,row in testpd.iterrows():\n",
        "    row = row.to_numpy()\n",
        "    #print(row)\n",
        "    r = int(row[2])\n",
        "    g = int(row[3])\n",
        "    b = int(row[4])\n",
        "    if r < 0:\n",
        "      r += 256\n",
        "    if g < 0:\n",
        "      g += 256\n",
        "    if b < 0:\n",
        "      b += 256\n",
        "    #print(f\"r: {r}\")\n",
        "    hue.append(huecalc(r,g,b))\n",
        "    sat.append(satcalc(r,g,b))\n",
        "    light.append(lightness(r,g,b))\n",
        "    val.append(rgb_val(r,g,b))\n",
        "    #print(row)\n",
        "  #print(hue)\n",
        "  testpd.insert(len(testpd.columns), \"hue\", hue)\n",
        "  testpd.insert(len(testpd.columns), \"saturation\", sat)\n",
        "  testpd.insert(len(testpd.columns), \"lightness\", light)\n",
        "  testpd.insert(len(testpd.columns), \"val\", val)\n",
        "\n",
        "  testpd['distance'] /= 255\n",
        "\n",
        "\n",
        "  return testpd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrkYkL_zIVRx"
      },
      "outputs": [],
      "source": [
        "def curvecheck(sat, light):\n",
        "  a = ((light/sat)-1)/(sat-1)\n",
        "  b = 1-a\n",
        "\n",
        "  xarr = np.asarray([0.1*i for i in range(10)])\n",
        "  xarr += sat\n",
        "  yarr = [a*x**2 + b*x for x in xarr]\n",
        "\n",
        "  return xarr, yarr\n",
        "  #double check this function, I ran into some issues with the curves going out of bounds at the boundary conditions\n",
        "\n",
        "def hsl_distance(hsl_1, hsl_2):\n",
        "  coord1 = (hsl_1[1]*np.cos(np.deg2rad(hsl_1[0])),hsl_1[1]*np.sin(np.deg2rad(hsl_1[0])), hsl_1[2])\n",
        "  coord2 = (hsl_2[1]*np.cos(np.deg2rad(hsl_2[0])),hsl_2[1]*np.sin(np.deg2rad(hsl_2[0])), hsl_2[2])\n",
        "\n",
        "  return math.sqrt((coord1[0]-coord2[0])**2+(coord1[1]-coord2[1])**2+(coord1[2]-coord2[2])**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLpY4P8XLIhg"
      },
      "outputs": [],
      "source": [
        "from operator import indexOf\n",
        "\n",
        "def get_freqtable(colornames, color_df, color_quant = 0.2):\n",
        "  freqtable = np.asarray([[name, len(color_df[color_df['name']==name]), round(color_df[color_df['name']==name]['hue'].mean(),3), round(color_df[color_df['name']==name]['saturation'].mean(),3), round(color_df[color_df['name']==name]['lightness'].mean(),3), round(color_df[color_df['name']==name]['distance'].mean(),4)] for name in colornames])\n",
        "  freqtable = pd.DataFrame(columns = [\"name\", \"freq\",\"avg_hue\",\"avg_saturation\",\"avg_lightness\", \"avg_distance\"], data= freqtable)\n",
        "  freqtable[\"freq\"]= pd.to_numeric(freqtable[\"freq\"])\n",
        "  freqtable.dropna()\n",
        "  freqtable = freqtable[freqtable['freq'] != 0]\n",
        "  freqtable[\"avg_hue\"] = pd.to_numeric(freqtable[\"avg_hue\"])\n",
        "  freqtable[\"avg_saturation\"]  = pd.to_numeric(freqtable[\"avg_saturation\"])\n",
        "  freqtable[\"avg_lightness\"]= pd.to_numeric(freqtable[\"avg_lightness\"])\n",
        "  freqtable[\"avg_distance\"]= pd.to_numeric(freqtable[\"avg_distance\"])\n",
        "  return freqtable\n",
        "\n",
        "def swath_gen(h,xarr, yarr,rank, distrib):\n",
        "  vals = [0,1,2,3,4,5,6,7,8,9]\n",
        "  swatharr = tuple(zip(distrib, vals))\n",
        "  xarr = list(xarr)\n",
        "  yarr = list(yarr)\n",
        "  if len(yarr) == 1:\n",
        "    yarr = yarr[0]\n",
        "  if len(xarr) == 1:\n",
        "    xarr = xarr[0]\n",
        "  keylist = sorted(swatharr, key = lambda x:x[0])\n",
        "  top_n = 0\n",
        "  if rank == \"60\":\n",
        "    #print(swatharr)\n",
        "    top_n = 3\n",
        "    \n",
        "\n",
        "  elif rank == \"30\":\n",
        "    top_n = 2\n",
        "\n",
        "  elif rank == \"10\":\n",
        "    top_n = 1\n",
        "  else:\n",
        "    print(f\"Invalid rank: {rank}\")\n",
        "    return []\n",
        "  keylist = [swatharr[i][1] for i in range(top_n)]\n",
        "  #print(f\"xarr: {xarr}\")\n",
        "  #print(f\"yarr: {yarr}\")\n",
        "  additional= [[h,xarr[i],yarr[i]] for i in keylist]\n",
        "  return additional\n",
        "\n",
        "def get_colordf(testcombo, color_quant = .1):\n",
        "  colornames = testcombo['name'].unique()\n",
        "  if testcombo[\"saturation\"].mean() > 0.5:\n",
        "    satbool = testcombo[\"saturation\"] < testcombo[\"saturation\"].quantile(1-color_quant)\n",
        "  else:\n",
        "    satbool = testcombo[\"saturation\"] > testcombo[\"saturation\"].quantile(color_quant)\n",
        "  \n",
        "  if testcombo[\"lightness\"].mean() > 0.5:\n",
        "    lightbool = testcombo[\"lightness\"] < testcombo[\"lightness\"].quantile(1-color_quant)\n",
        "  else:\n",
        "    lightbool = testcombo[\"lightness\"] > testcombo[\"lightness\"].quantile(color_quant)\n",
        "  color_df = testcombo[lightbool & satbool]\n",
        "  return colornames, color_df\n",
        "def get_rankingdf(distance_df, color):\n",
        "  ranking_df = distance_df.copy()\n",
        "  ranking_df.drop(\"subtype\", axis = 1, inplace = True)\n",
        "  ranking_df = ranking_df[['prim_color','type', \"score\"]]\n",
        "  ranking_df = ranking_df.groupby(\"type\").aggregate([\"sum\"]).sort_values(('score','sum'), ascending = True)\n",
        "  ranking_df.columns = [ \"prim_color\", \"score\"]\n",
        "  ranking_df[\"prim_color\"] = [color for _ in range(len(ranking_df))]\n",
        "  ranking_df['score']/=ranking_df['score'].sum()\n",
        "  self_score = ranking_df.iloc[0][\"score\"]\n",
        "  #print(ranking_df.index)\n",
        "  ranking_df=ranking_df.drop('Self')\n",
        "  ranking_df['score']/=ranking_df['score'].sum()\n",
        "\n",
        "  return ranking_df\n",
        "\n",
        "def n_mostcommon(color_df, rgb_list, n):\n",
        "  rgb_count = []\n",
        "  for rgb in rgb_list:\n",
        "    num_rgb = len(color_df[(abs(color_df[\"R\"]-rgb[0]) < 5) & (abs(color_df[\"G\"]-rgb[1]) < 5) & (abs(color_df[\"B\"]-rgb[2]) < 0.05)])\n",
        "    rgb_count.append([rgb, rgb_count])\n",
        "  rgb_count = sorted(rgb_count, key = lambda x:x[1])\n",
        "  return list(np.asarray(rgb_count)[:n,0])\n",
        "def hue_distance_calc(h,xarr,yarr,df):\n",
        "  lim = 400\n",
        "\n",
        "  #print(\"hdc\")\n",
        "  #clock = ticktock()\n",
        "  #clock.tick()\n",
        "  hslarr = [[h, xarr[i],yarr[i]] for i in range(len(xarr))]\n",
        "  distance = 0\n",
        "  freqlist = [0,0,0,0,0,0,0,0,0,0]\n",
        "  if len(df) < lim:\n",
        "    for index,row in df.iterrows():\n",
        "      temp_d = []\n",
        "      \n",
        "      row_hsl = [row[\"hue\"],row[\"saturation\"], row[\"lightness\"]]\n",
        "      for trip in hslarr:\n",
        "        temp_d.append(hsl_distance(trip, row_hsl))\n",
        "      distance += min(temp_d)\n",
        "      freqlist[temp_d.index(min(temp_d))] += 1\n",
        "    #clock.tock()\n",
        "    #print(\"hdc end\")\n",
        "  else:\n",
        "    for i in range(lim):\n",
        "      index = random.randint(0, len(df)-1)\n",
        "      row = df.iloc[index]\n",
        "      \n",
        "      temp_d = []\n",
        "      \n",
        "      row_hsl = [row[\"hue\"],row[\"saturation\"], row[\"lightness\"]]\n",
        "      for trip in hslarr:\n",
        "        temp_d.append(hsl_distance(trip, row_hsl))\n",
        "      distance += min(temp_d)\n",
        "      freqlist[temp_d.index(min(temp_d))] += 1\n",
        "    #clock.tock()\n",
        "  return distance, np.asarray(freqlist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7di1p9BZykd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_pallette(color_df, color, freqtable, color_quant = 0.1, pal_limit = 0.9, palette_length = 6):\n",
        "  \n",
        "  \n",
        "  clock = ticktock()\n",
        "\n",
        "  \n",
        "  color_hue = float(freqtable[freqtable['name'] == color]['avg_hue'])\n",
        "\n",
        "  comphue = (color_hue-180)%360\n",
        "  analagous_hue1 = (color_hue-30)%360\n",
        "  analagous_hue2 = (color_hue+30)%360\n",
        "  triadic_hue1 = (color_hue-120)%360\n",
        "  triadic_hue2 = (color_hue+120)%360\n",
        "  split_hue1 = (color_hue+150)%360\n",
        "  split_hue2 = (color_hue-150)%360\n",
        "  square_hue1 = (color_hue+90)%360\n",
        "  square_hue2 = (color_hue-90)%360\n",
        "\n",
        "  \n",
        "  self_df = color_df[abs(color_df['hue']-color_hue) < 30]\n",
        "  complementary_df =  color_df[abs(color_df['hue']-comphue) < 30]\n",
        "  anal_df1 = color_df[abs(color_df['hue']-analagous_hue1) < 15]\n",
        "  anal_df2 = color_df[abs(color_df['hue']-analagous_hue2) < 15]\n",
        "  tri_df1 = color_df[abs(color_df['hue']-triadic_hue1) < 15]\n",
        "  tri_df2 = color_df[abs(color_df['hue']-triadic_hue2) < 15]\n",
        "  split_df1 = color_df[abs(color_df['hue']-split_hue1) < 15]\n",
        "  split_df2 = color_df[abs(color_df['hue']-split_hue2) < 15]\n",
        "  square_df1 = color_df[abs(color_df['hue']-comphue) < 20]\n",
        "  square_df2 = color_df[abs(color_df['hue']-square_hue1) < 5]\n",
        "  square_df3 = color_df[abs(color_df['hue']-square_hue2) < 5]\n",
        "  tetra_df1 = color_df[abs(color_df['hue']-comphue) < 20] #used for both tetras\n",
        "  tetra_df1_2 = color_df[abs(color_df['hue']-analagous_hue1) < 5]\n",
        "  tetra_df1_3 = color_df[abs(color_df['hue']-split_hue1) < 5]\n",
        "  tetra_df2_2 = color_df[abs(color_df['hue']-analagous_hue2) < 5]\n",
        "  tetra_df2_3 = color_df[abs(color_df['hue']-split_hue2) < 5]\n",
        "\n",
        "\n",
        "\n",
        "  self_count = len(self_df)\n",
        "  complementary_count = len(complementary_df)\n",
        "  anal_count1 =  len(anal_df1) \n",
        "  anal_count2 = len(anal_df2)\n",
        "  triadic_count1 = len(tri_df1)\n",
        "  triadic_count2  = len(tri_df2)\n",
        "\n",
        "  split_count1 = len(split_df1)\n",
        "  split_count2 = len(split_df2)\n",
        "\n",
        "  square_count1 =  len(square_df1)\n",
        "  square_count2 =  len(square_df2)\n",
        "  square_count3 =  len(square_df3)\n",
        "\n",
        "  tetradic_count1_1 = len(tetra_df1)\n",
        "  tetradic_count1_2 = len(tetra_df1_2)\n",
        "  tetradic_count1_3 = len(tetra_df1_3)\n",
        "  tetradic_count2_1 = len(tetra_df1)\n",
        "  tetradic_count2_2 = len(tetra_df2_2)\n",
        "  tetradic_count2_3 = len(tetra_df2_3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #freqtable[abs(freqtable['avg_hue']-30) < 10].sort_values(by='freq', ascending = False)\n",
        "\n",
        "\n",
        "  og_sat = float(freqtable[freqtable['name'] == color]['avg_saturation'])\n",
        "  og_light = float(freqtable[freqtable['name'] == color]['avg_lightness'])\n",
        "  xarr,yarr = curvecheck(og_sat,og_light)\n",
        "\n",
        "\n",
        "\n",
        "  freqlist_arr = [[] for i in range(17)]\n",
        "\n",
        "\n",
        "  #clock.tick()\n",
        "\n",
        "  self_distance,freqlist_arr[0] = hue_distance_calc(color_hue, xarr, yarr, self_df)\n",
        "  comp_distance,freqlist_arr[1] = hue_distance_calc(comphue, xarr, yarr, complementary_df)\n",
        "  anal_distance1,freqlist_arr[2]= hue_distance_calc(analagous_hue1, xarr, yarr, anal_df1)\n",
        "  anal_distance2 ,freqlist_arr[3]= hue_distance_calc(analagous_hue2, xarr, yarr, anal_df2)\n",
        "  tri_distance1 ,freqlist_arr[4]= hue_distance_calc(triadic_hue1, xarr, yarr, tri_df1)\n",
        "  tri_distance2 ,freqlist_arr[5]= hue_distance_calc(triadic_hue2, xarr, yarr, tri_df2)\n",
        "  split_distance1 ,freqlist_arr[6]= hue_distance_calc(split_hue1, xarr, yarr, split_df1)\n",
        "  split_distance2 ,freqlist_arr[7]= hue_distance_calc(split_hue2, xarr, yarr, split_df2)\n",
        "  square_distance1 ,freqlist_arr[8]= hue_distance_calc(comphue, xarr, yarr, square_df1)\n",
        "  square_distance2 ,freqlist_arr[9]= hue_distance_calc(square_hue1, xarr, yarr, square_df2)\n",
        "  square_distance3,freqlist_arr[10] = hue_distance_calc(square_hue2, xarr, yarr, square_df3)\n",
        "  tetra_distance1,freqlist_arr[11] = hue_distance_calc(comphue, xarr, yarr, tetra_df1)\n",
        "  tetra_distance1_2,freqlist_arr[12] = hue_distance_calc(analagous_hue1, xarr, yarr, tetra_df1_2)\n",
        "  tetra_distance1_3 ,freqlist_arr[13]= hue_distance_calc(split_hue1, xarr, yarr, tetra_df1_3)\n",
        "  tetra_distance1,freqlist_arr[14] = hue_distance_calc(comphue, xarr, yarr, tetra_df1)\n",
        "  tetra_distance2_2 ,freqlist_arr[15]= hue_distance_calc(analagous_hue2, xarr, yarr, tetra_df2_2)\n",
        "  tetra_distance2_3,freqlist_arr[16] = hue_distance_calc(split_hue2, xarr, yarr, tetra_df2_3)\n",
        "\n",
        "  #clock.tock()\n",
        "\n",
        "\n",
        "  freqlist_arr = np.asarray(freqlist_arr).T\n",
        "  columns = [\"prim_color\", \"type\", \"subtype\", \"count\", \"count%\", \"avg_distance\", \"hue_arr\",\"f1\", \"f2\", \"f3\", \"f4\",\"f5\",\"f6\",\"f7\",\"f8\", \"f9\", \"f10\"]\n",
        "  prim_color = np.asarray([color for _ in range(17)]).T\n",
        "  typearr = np.asarray([\"Self\",\"Comp\", \"Analg\", \"Analg\", \"Tri\", \"Tri\", \"Split\", \"Split\", \"Square\", \"Square\", \"Square\", \"Tetra1\", \"Tetra1\", \"Tetra1\", \"Tetra2\", \"Tetra2\", \"Tetra2\"]).T\n",
        "  subtypearr = np.asarray([\"\", \"\", \"-\", \"+\", \"-\", \"+\", \"+\", \"-\", \"comp\", \"+\", \"-\", \"comp\", \"-\", \"- comp\", \"comp\", \"+\", \"+ comp\"]).T\n",
        "  count = np.asarray([self_count, complementary_count,anal_count1,anal_count2, triadic_count1, triadic_count2, split_count1, split_count2, square_count1, square_count2, square_count3, tetradic_count1_1, tetradic_count1_2, tetradic_count1_3, tetradic_count2_1, tetradic_count2_2, tetradic_count2_3]).T\n",
        "  count_perc = count/count.sum()\n",
        "  avg_distance = np.asarray([self_distance, comp_distance, anal_distance1, anal_distance2, tri_distance1, tri_distance2, split_distance1, split_distance2, square_distance1, square_distance2, square_distance3,\n",
        "                  tetra_distance1, tetra_distance1_2, tetra_distance1_3, tetra_distance1, tetra_distance2_2, tetra_distance2_3]).T\n",
        "\n",
        "  hue_arr = [[color_hue], [comphue],[analagous_hue1, analagous_hue2],[analagous_hue1, analagous_hue2],\n",
        "             [triadic_hue1, triadic_hue2],[triadic_hue1, triadic_hue2],[split_hue2, split_hue1],\n",
        "             [split_hue2, split_hue1],[comphue, square_hue2, square_hue1],[comphue, square_hue2, square_hue1],\n",
        "             [comphue, square_hue2, square_hue1], [comphue, analagous_hue1, split_hue1],[comphue, analagous_hue1, split_hue1],\n",
        "             [comphue, analagous_hue1, split_hue1], [comphue, analagous_hue2, split_hue2],[comphue, analagous_hue2, split_hue2],\n",
        "             [comphue, analagous_hue2, split_hue2]]\n",
        "\n",
        "  distance_df = pd.DataFrame(columns = columns, data = np.asarray([prim_color, typearr, subtypearr, count, count_perc ,avg_distance,hue_arr,\n",
        "                                                                  freqlist_arr[0], freqlist_arr[1], freqlist_arr[2], freqlist_arr[3],\n",
        "                                                                  freqlist_arr[4], freqlist_arr[5], freqlist_arr[6], freqlist_arr[7],\n",
        "                                                                  freqlist_arr[8], freqlist_arr[9]]).T)\n",
        "  distance_df[\"count\"] = pd.to_numeric(distance_df[\"count\"])\n",
        "  distance_df[\"avg_distance\"] = pd.to_numeric(distance_df[\"avg_distance\"])\n",
        "  distance_df[\"count\"] = pd.to_numeric(distance_df[\"count\"])\n",
        "  distance_df[\"f1\"] = pd.to_numeric(distance_df[\"f1\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f2\"] = pd.to_numeric(distance_df[\"f2\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f3\"] = pd.to_numeric(distance_df[\"f3\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f4\"] = pd.to_numeric(distance_df[\"f4\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f5\"] = pd.to_numeric(distance_df[\"f5\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f6\"] = pd.to_numeric(distance_df[\"f6\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f7\"] = pd.to_numeric(distance_df[\"f7\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f8\"] = pd.to_numeric(distance_df[\"f8\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f9\"] = pd.to_numeric(distance_df[\"f9\"])/distance_df[\"count\"]\n",
        "  distance_df[\"f10\"] = pd.to_numeric(distance_df[\"f10\"])/distance_df[\"count\"]\n",
        "  distance_df[\"avg_distance\"] /= distance_df[\"count\"]\n",
        "\n",
        "\n",
        "  #clock.tock()\n",
        "\n",
        "\n",
        "  k_exp = 1.4 #constant, balancing out the score\n",
        "  score = distance_df[\"count\"]*np.exp(distance_df[\"avg_distance\"]*-1*k_exp)\n",
        "  distance_df.insert(len(distance_df.columns), 'score',np.asarray(score))\n",
        "  \n",
        "\n",
        "  #clock.tock()\n",
        "\n",
        "\n",
        "\n",
        "  return distance_df, color_hue, xarr, yarr "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2qoCdhR2blH"
      },
      "outputs": [],
      "source": [
        "def construct_palette(pal_limit, ranking_df, distance_df, xarr, yarr, currtype, standard,color_df,palette_length=6):\n",
        "\n",
        "\n",
        "  #print(distance_df[distance_df['type'] == currtype]['hue_arr'].iloc[0])\n",
        "  hue_arr = list(distance_df[distance_df['type'] == currtype]['hue_arr'].iloc[0])\n",
        "  \n",
        "  #print(hue_arr)\n",
        "  #print(type(hue_arr))\n",
        "  #print(currtype)\n",
        "  #print(\"----------------------\")\n",
        "  curr_df = distance_df[distance_df[\"type\"] == currtype]\n",
        "  num_colors = len(curr_df)\n",
        "  if currtype == \"Analg\":\n",
        "    minus_arr = curr_df[curr_df['subtype'] == \"-\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    plus_arr = curr_df[curr_df['subtype'] == \"+\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    ratio = float(curr_df[curr_df['subtype'] == \"-\"]['score'])/float(curr_df[curr_df['subtype'] == \"+\"]['score'])\n",
        "    #print(curr_df[curr_df['subtype'] == \"-\"]['score'])\n",
        "    #print(curr_df[curr_df['subtype'] == \"+\"]['score'])\n",
        "    #print(ratio)\n",
        "    if ratio > 2.5:\n",
        "      #- is 30, + is 10\n",
        "      #[analagous_hue1, analagous_hue2]\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", plus_arr)\n",
        "    elif ratio < .4:\n",
        "      #- is 10, + is 30\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", plus_arr)\n",
        "    else:\n",
        "      #- is 30, + is 30\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", plus_arr)\n",
        "  elif currtype == \"Tetra1\":\n",
        "    comp_arr = curr_df[curr_df['subtype'] == \"comp\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    minus_arr = curr_df[curr_df['subtype'] == \"-\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    minus_comp_arr = curr_df[curr_df['subtype'] == \"-comp\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "\n",
        "    if float(curr_df['score'].max()) == float(curr_df[curr_df['subtype'] == \"comp\"]['score']):\n",
        "      #[comphue, analagous_hue1, split_hue1]\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", minus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"10\", minus_comp_arr)\n",
        "    elif float(curr_df['score'].max()) == float(curr_df[curr_df['subtype'] == \"-\"]['score']):\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", minus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"10\", minus_comp_arr)\n",
        "    else:\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", minus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"30\", minus_comp_arr)\n",
        "  elif currtype == \"Tri\":\n",
        "    minus_arr = curr_df[curr_df['subtype'] == \"-\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    plus_arr = curr_df[curr_df['subtype'] == \"+\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    ratio = float(curr_df[curr_df['subtype'] == \"-\"]['score'])/float(curr_df[curr_df['subtype'] == \"+\"]['score'])\n",
        "    if ratio > 2.5:\n",
        "      #- is 30, + is 10\n",
        "      #[triadic_hue1, triadic_hue2]\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", plus_arr)\n",
        "    elif ratio < .4:\n",
        "      #- is 10, + is 30\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", plus_arr)\n",
        "    else:\n",
        "      #- is 30, + is 30\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", plus_arr)\n",
        "  elif currtype == \"Square\":\n",
        "    comp_arr = curr_df[curr_df['subtype'] == \"comp\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    minus_arr = curr_df[curr_df['subtype'] == \"-\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    plus_arr = curr_df[curr_df['subtype'] == \"+\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "\n",
        "    if float(curr_df['score'].max()) == float(curr_df[curr_df['subtype'] == \"comp\"]['score']):\n",
        "      #[comphue, square_hue2, square_hue1]\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", minus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"10\", plus_arr)\n",
        "    elif float(curr_df['score'].max()) == float(curr_df[curr_df['subtype'] == \"-\"]['score']):\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", minus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"10\", plus_arr)\n",
        "    else:\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", minus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"30\", plus_arr)\n",
        "\n",
        "  elif currtype == \"Tetra2\":\n",
        "    comp_arr = curr_df[curr_df['subtype'] == \"comp\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    plus_arr = curr_df[curr_df['subtype'] == \"+\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    plus_comp_arr = curr_df[curr_df['subtype'] == \"+comp\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "\n",
        "    if float(curr_df['score'].max()) == float(curr_df[curr_df['subtype'] == \"comp\"]['score']):\n",
        "      #[comphue, analagous_hue2, split_hue2]\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", plus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"10\", plus_comp_arr)\n",
        "    elif float(curr_df['score'].max()) == float(curr_df[curr_df['subtype'] == \"+\"]['score']):\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", plus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"10\", plus_comp_arr)\n",
        "    else:\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", comp_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", plus_arr)\n",
        "      swath3 = swath_gen(hue_arr[2], xarr,yarr, \"30\", plus_comp_arr)\n",
        "\n",
        "  elif currtype == \"Split\":\n",
        "    minus_arr = curr_df[curr_df['subtype'] == \"-\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    plus_arr = curr_df[curr_df['subtype'] == \"+\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    ratio = float(curr_df[curr_df['subtype'] == \"-\"]['score'])/float(curr_df[curr_df['subtype'] == \"+\"]['score'])\n",
        "    if ratio > 2.5:\n",
        "      #- is 30, + is 10\n",
        "      #[split_hue2, split_hue1]\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"10\", plus_arr)\n",
        "    elif ratio < .4:\n",
        "      #- is 10, + is 30\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"10\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", plus_arr)\n",
        "    else:\n",
        "      #- is 30, + is 30\n",
        "      swath1 = swath_gen(hue_arr[0], xarr,yarr, \"30\", minus_arr)\n",
        "      swath2 = swath_gen(hue_arr[1], xarr,yarr, \"30\", plus_arr)\n",
        "  elif currtype == \"Comp\":\n",
        "    #[comphue]\n",
        "    rank_arr = curr_df[curr_df['type'] == \"Comp\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']]\n",
        "    swath1 = swath_gen(hue_arr[0], xarr,yarr, \"60\", rank_arr)\n",
        "  else:\n",
        "    print(f\"Invalid type: {currtype} (check for spelling errors)\")\n",
        "\n",
        "\n",
        "  hexarr = list(standard)[0]\n",
        "  for color_part in swath1:\n",
        "    hexarr.append(tuple(convert_hsl_to_rgb(color_part)))\n",
        "  if num_colors > 1:\n",
        "    for color_part in swath2:\n",
        "      hexarr.append(tuple(convert_hsl_to_rgb(color_part)))\n",
        "  if num_colors > 2:\n",
        "    for color_part in swath3:\n",
        "      hexarr.append(tuple(convert_hsl_to_rgb(color_part)))\n",
        "\n",
        "  \n",
        "\n",
        "  #print(hexarr)\n",
        "  #print(indices)\n",
        "  #print(hexarr[indices])\n",
        "  hexset = set(hexarr)\n",
        "  hexarr = list(hexset)\n",
        "  hexarr = np.asarray(hexarr)\n",
        "  #print(hexarr)\n",
        "  hexarr = np.asarray(n_mostcommon(color_df, hexarr, palette_length))\n",
        "\n",
        "  indices = np.linspace(0,len(hexarr)-1, len(hexarr)).reshape(1,len(hexarr)).astype(int)\n",
        "  #print(hexarr)\n",
        "  plt.imshow(hexarr[indices])\n",
        "\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djBuVGvJJv7x"
      },
      "outputs": [],
      "source": [
        "class ticktock:\n",
        "  def __init__(self):\n",
        "    self.totstart=  time.time()\n",
        "    self.start = time.time()\n",
        "    self.end = time.time()\n",
        "  def tick(self):\n",
        "    self.start = time.time()\n",
        "    selfend = time.time()\n",
        "  def tock(self, tocktick = True, print_time = True):\n",
        "    self.end = time.time()\n",
        "    timepassed = self.end-self.start\n",
        "    if print_time: \n",
        "      print(f\"{timepassed} seconds passed\")\n",
        "    if tocktick:\n",
        "      self.start = time.time()\n",
        "    return timepassed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a76wP3qFKnON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "f0f76c37-05df-4eea-ebbb-0514b8c7d2a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'url = \"https://www.pinterest.com/miraculouswip/posters/\"\\nnumsamples = 500\\ntestcombo = assemble_df_direct(url, numsamples)\\ncolornames, color_df = get_colordf(testcombo,0.4)\\nfreqtable = get_freqtable(colornames,color_df, color_quant = 0.4)\\nfreqtable.sort_values(by = \\'freq\\', inplace = True, ascending = False)\\nname = colornames[0]\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "'''url = \"https://www.pinterest.com/miraculouswip/posters/\"\n",
        "numsamples = 500\n",
        "testcombo = assemble_df_direct(url, numsamples)\n",
        "colornames, color_df = get_colordf(testcombo,0.4)\n",
        "freqtable = get_freqtable(colornames,color_df, color_quant = 0.4)\n",
        "freqtable.sort_values(by = 'freq', inplace = True, ascending = False)\n",
        "name = colornames[0]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8XP_j7zJrZs"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def pinterest_palette(url = 'https://www.pinterest.com/miraculouswip/granola-stuff/', numsamples = 1000,  color_quant = 0.4):\n",
        "  clock = ticktock()\n",
        "  \n",
        "  \n",
        "  print(\"fetching image files...\")\n",
        "  clock.tick()\n",
        "  '''\n",
        "  \n",
        "  result = getImageFiles(url)\n",
        "  clock.tock()\n",
        "  \n",
        "  print(\"assembling pixel counts...\")\n",
        "  testcombo = assemble_df(result[0], result[1], numsamples)\n",
        "\n",
        "  clock.tock()\n",
        "  '''\n",
        "  testcombo = assemble_df_direct(url, numsamples)\n",
        "  print(testcombo)\n",
        "  clock.tock()\n",
        " \n",
        "  print(\"filtering data...\")\n",
        "  colornames, color_df = get_colordf(testcombo,color_quant)\n",
        "\n",
        "  clock.tock()\n",
        "\n",
        "  freqtable = get_freqtable(colornames,color_df, color_quant = color_quant)\n",
        "  freqtable.sort_values(by = 'freq', inplace = True, ascending = False)\n",
        "  clock.tock()\n",
        "  print(\"counting color frequency...\")\n",
        "\n",
        "  pal_limit=0.9\n",
        "  distance_df_arr = []\n",
        "  ranking_df_arr = []\n",
        "  xy_arr = []\n",
        "  clock.tock()\n",
        "  for name in freqtable.head(10)[\"name\"]:\n",
        "    clock.tock()\n",
        "    print(f\"Computing color palettes for {name}\")\n",
        "    #print(f\"|    {name}        |\\n--------------------------\")\n",
        "    distance_df, color_hue, xarr, yarr = get_pallette(color_df, name, freqtable)\n",
        "    clock.tock()\n",
        "    print(f\"Ranking {name}\")\n",
        "    ranking_df = get_rankingdf(distance_df, name)\n",
        "    distance_df_arr.append(distance_df)\n",
        "    ranking_df_arr.append(ranking_df)\n",
        "    clock.tock()\n",
        "    selflist = list(distance_df[distance_df[\"type\"] == \"Self\"][[\"f1\",'f2','f3','f4',\"f5\",'f6','f7','f8',\"f9\",'f10']].iloc[0])\n",
        "    standard= swath_gen(color_hue, xarr, yarr, \"60\",selflist)\n",
        "    for s in range(len(standard)):\n",
        "      standard[s] = tuple(convert_hsl_to_rgb(standard[s]))\n",
        "    \n",
        "    xy_arr.append([name, xarr, yarr, standard])\n",
        "    currtype = \"Tri\"\n",
        "    #temporarily^\n",
        "  \n",
        "\n",
        "  tot_distancedf = pd.concat(distance_df_arr, sort = False)\n",
        "  tot_rankingdf = pd.concat(ranking_df_arr, sort = False)\n",
        "\n",
        "  clock.tock()\n",
        "  print(\"Computing best palettes\")\n",
        "  tot_distancedf = tot_distancedf.merge(freqtable[['name', 'freq']], how='inner', left_on = \"prim_color\", right_on = \"name\")\n",
        "  #total_score = tot_distancedf[\"score\"]*tot_distancedf[\"freq\"]\n",
        "\n",
        "  tot_distancedf['freq'] = pd.to_numeric(tot_distancedf['freq']).astype(float)\n",
        "\n",
        "  \n",
        "\n",
        "  sqrtscore = np.sqrt(tot_distancedf['freq'])\n",
        "\n",
        "  tot_score = sqrtscore*tot_distancedf['score']\n",
        "\n",
        "  tot_distancedf.insert(len(tot_distancedf.columns), \"tot_score\",tot_score,True)\n",
        "\n",
        "  xy_df = pd.DataFrame(columns = [\"name\", \"xarr\", \"yarr\", \"standard\"], data = xy_arr)\n",
        "\n",
        "\n",
        "  tot_distancedf.sort_values(by='tot_score', inplace = True, ascending = False)\n",
        "\n",
        "  iterdf = tot_distancedf[tot_distancedf[\"type\"] != 'Self']\n",
        "  iterdf.reset_index(inplace = True)\n",
        "\n",
        "  #print(iterdf.index)\n",
        "\n",
        "\n",
        "  clock.tock()\n",
        "  for i in range(10):\n",
        "    tempname = str(iterdf.iloc[i][\"name\"])\n",
        "    temptype = iterdf.iloc[i][\"type\"]\n",
        "    print(f\"rank {i+1}:{tempname}, {temptype}        |\\n--------------------------\")\n",
        "    construct_palette(pal_limit, iterdf[iterdf[\"prim_color\"] == tempname], iterdf[iterdf[\"prim_color\"] == tempname], xy_df[xy_df[\"name\"] == tempname][\"xarr\"], xy_df[xy_df[\"name\"] == tempname][\"yarr\"], temptype, xy_df[xy_df[\"name\"] == tempname][\"standard\"], color_df)\n",
        "    #print(iterdf.iloc[i][\"name\"])\n",
        "  clock.tock()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfm8LBOd_PYH"
      },
      "outputs": [],
      "source": [
        "\n",
        "#add ur URL HERE!!!!\n",
        "\n",
        "pinterest_palette('https://www.pinterest.com/miraculouswip/kattar-3adik/', numsamples = 500, color_quant = 0.22)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "pinterest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}